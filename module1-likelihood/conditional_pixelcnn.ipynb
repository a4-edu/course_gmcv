{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1. Likelihood-based models\n",
    "\n",
    "- Seminar (10 points): Autoregressive Transformer\n",
    "- **Task 1 (10 points): PixelCNN**\n",
    "    - Unconditional (5 points)\n",
    "    - **Conditional (5 points)**\n",
    "- Task 2 (10 points): RealNVP\n",
    "- \\* Bonus (10+++ points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2. Conditional PixelCNNs on Shapes and MNIST\n",
    "\n",
    "In this part, implement and train a **class-conditional** PixelCNN on binary MNIST. Condition on a class label by adding a conditional bias in each convolutional layer. More precisely, in the $\\ell$th convolutional layer, compute: \n",
    "$$W_\\ell * x + b_\\ell + V_\\ell y$$\n",
    "where $W_\\ell * x + b_\\ell$ is a masked convolution (as in previous parts), $V$ is a 2D weight matrix, and $y$ is a one-hot encoding of the class label (where the conditional bias is broadcasted spacially and added channel-wise). You may need `nn.Embedding` here\n",
    "\n",
    "You can use a PixelCNN architecture similar to Task 1.1. Training on the shapes dataset should be quick, and MNIST should take around 10-15 minutes\n",
    "\n",
    "Feel free to use and modify any sources from Task 1.1\n",
    "\n",
    "**You will provide these deliverables**\n",
    "\n",
    "\n",
    "1.   Over the course of training, record the average negative log-likelihood (nats / dim) of the training data (per minibatch) and test data (for your entire test set). Code is provided that automatically plots the training curves. \n",
    "2.   Report the final test set performance of your final model\n",
    "3. 100 samples from the final trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "\n",
    "def show_samples(samples, nrow=10, title='Samples'):\n",
    "    samples = (torch.FloatTensor(samples)).permute(0, 3, 1, 2)\n",
    "    grid_img = make_grid(samples, nrow=nrow)\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.imshow(grid_img.permute(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "        \n",
    "\n",
    "def load_data(fname, binarize=True, include_labels=False):\n",
    "    with open(fname, 'rb') as data_file:\n",
    "        data = pickle.load(data_file)\n",
    "    \n",
    "    if include_labels:\n",
    "        return (data['train'] > 127.5), (data['test'] > 127.5), data['train_labels'], data['test_labels']\n",
    "    \n",
    "    return (data['train'] > 127.5), (data['test'] > 127.5)\n",
    "\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        assert len(X) == len(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For colab users: download data\n",
    "# ! wget https://github.com/a4-edu/course_gmcv/raw/hw1/module1-likelihood/shapes.pkl\n",
    "# ! wget https://github.com/a4-edu/course_gmcv/raw/hw1/module1-likelihood/mnist.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# MANY OF YOUR CODE HERE\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, train_labels, test_data, test_labels, num_classes, model):\n",
    "    \"\"\"\n",
    "    train_data: A (n_train, H, W, 1) uint8 numpy array of binary images with values in {0, 1}\n",
    "    train_labels: A (n_train, 1) int64 numpy array or image labels with values in {0, 1, ..., num_classes - 1}\n",
    "    test_data: A (n_test, H, W, 1) uint8 numpy array of binary images with values in {0, 1}\n",
    "    test_labels: A (n_test, 1) int64 numpy array or image labels with values in {0, 1, ..., num_classes - 1}\n",
    "    num_classes: int\n",
    "    model: nn.Model item\n",
    "    Returns\n",
    "    - a (# of training iterations,) numpy array of train_losses evaluated every minibatch\n",
    "    - a (# of epochs + 1,) numpy array of test_losses evaluated once at initialization and after each epoch\n",
    "    - trained model\n",
    "    \"\"\"\n",
    "    ################\n",
    "    # YOUR CODE HERE\n",
    "    ###############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First dataset: **Shapes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes_train, shapes_test, shapes_labels_train, shapes_labels_test = \\\n",
    "    load_data('./shapes.pkl', include_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_samples(shapes_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = shapes_labels_train.max() + 1\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W, _ = shapes_train[0].shape\n",
    "model = ... \n",
    "train_losses, test_losses, shapes_model = train_model(\n",
    "    shapes_train, shapes_labels_train,\n",
    "    shapes_test, shapes_labels_test,\n",
    "    num_classes,\n",
    "    model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train_plots(train_losses, test_losses, title):\n",
    "    plt.figure()\n",
    "    n_epochs = len(test_losses) - 1\n",
    "    x_train = np.linspace(0, n_epochs, len(train_losses))\n",
    "    x_test = np.arange(n_epochs + 1)\n",
    "\n",
    "    plt.plot(x_train, train_losses, label='train loss')\n",
    "    plt.plot(x_test, test_losses, label='test loss')\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('NLL')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_train_plots(train_losses, test_losses, 'Shapes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0] * 25 + [1] * 25 + [2] * 25 + [3] * 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = shapes_model.sample(100, torch.tensor(labels, dtype=torch.long))\n",
    "show_samples(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second dataset: MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train, mnist_test, mnist_labels_train, mnist_labels_test = \\\n",
    "    load_data('./mnist.pkl', include_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_samples(mnist_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = mnist_labels_train.max() + 1\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W, _ = mnist_train[0].shape\n",
    "model = ...\n",
    "train_losses, test_losses, mnist_model = train_model(\n",
    "    mnist_train, mnist_labels_train,\n",
    "    mnist_test, mnist_labels_test,\n",
    "    num_classes,\n",
    "    model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_train_plots(train_losses, test_losses, 'MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(list(range(10)) * 10).reshape(10, 10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = mnist_model.sample(100, torch.tensor(labels, dtype=torch.long))\n",
    "show_samples(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
