{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408fcd1a-64ba-4b42-881e-944ad1973132",
   "metadata": {},
   "outputs": [],
   "source": [
    "!if [ -d deepul ]; then rm -Rf deepul; fi\n",
    "!git clone https://github.com/rll/deepul.git\n",
    "!pip install ./deepul\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685c8830-b60b-4775-bada-6a552849c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepul.hw4_helper import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f563e899-beac-4fd1-9071-1cfb11e553f1",
   "metadata": {},
   "source": [
    "# Question 1: Toy Dataset\n",
    "\n",
    "In this question, we will train a simple diffusion models a toy 2D dataset.\n",
    "\n",
    "Execute the cell below to visualize our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3920830-dab0-41ce-8e85-68a9e6e4201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_q1_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b44d848-2075-4819-8065-8216a74cb9ce",
   "metadata": {},
   "source": [
    "For code simplicity, we will train a continuous-time variant of the diffusion prompt. In practice training objectives and code between discrete-time and continuous-time diffusion models are similar.\n",
    "\n",
    "Given a data element $x$ and neural net $f_\\theta(x, t)$, implement the following diffusion training steps:\n",
    "1. Sample the diffusion timestep: $t \\sim \\text{Uniform}(0, 1)$\n",
    "2. Compute the noise-strength following a cosine schedule: $\\alpha_t = \\cos\\left(\\frac{\\pi}{2}t\\right), \\sigma_t = \\sin\\left(\\frac{\\pi}{2}t\\right)$\n",
    "3. Apply the forward process - Sample noise $\\epsilon \\sim N(0,I)$ (same shape as $x$) and compute noised $x_t = \\alpha_t x + \\sigma_t \\epsilon$\n",
    "4. Estimate $\\hat{\\epsilon} = f_\\theta(x_t, t)$\n",
    "5. Optimize the loss $L = \\lVert \\epsilon - \\hat{\\epsilon} \\rVert_2^2$. Here, it suffices to just take the mean over all dimensions.\n",
    "\n",
    "Note that for the case of continuous-time diffusion, the forward process is $x_{0\\to1}$ and reverse process is $x_{1\\to0}$\n",
    "\n",
    "Use an MLP for $f_\\theta$ to optimize the loss. You may find the following details helpful.\n",
    "* Normalize the data using mean and std computed from the train dataset\n",
    "* Train 100 epochs, batch size 1024, Adam with LR 1e-3 (100 warmup steps, cosine decay to 0)\n",
    "* MLP with 4 hidden layers and hidden size 64\n",
    "* Condition on t by concatenating it with input x (i.e. 2D x + 1D t = 3D cat(x, t))\n",
    "\n",
    "To sample, implement the standard DDPM sampler. You may find the equation from the [DDIM paper](https://arxiv.org/pdf/2010.02502.pdf) helpful, rewritten and re-formatted here for convenience.\n",
    "$$x_{t-1} = \\alpha_{t-1}\\left(\\frac{x_t - \\sigma_t\\hat{\\epsilon}}{\\alpha_t}\\right) + \\sqrt{\\sigma_{t-1}^2 - \\eta_t^2}\\hat{\\epsilon} + \\eta_t\\epsilon_t$$\n",
    "where $\\epsilon_t \\sim N(0, I)$ is random Gaussian noise. For DDPM, let\n",
    "$$\\eta_t = \\sigma_{t-1}/\\sigma_t\\sqrt{1 - \\alpha_t^2/\\alpha_{t-1}^2}$$\n",
    "To run the reverse process, start from $x_1 \\sim N(0, I)$ and perform `num_steps` DDPM updates (a hyperparameter), pseudocode below.\n",
    "```\n",
    "ts = linspace(1 - 1e-4, 1e-4, num_steps + 1)\n",
    "x = sample_normal\n",
    "for i in range(num_steps):\n",
    "    t = ts[i]\n",
    "    tm1 = ts[i + 1]\n",
    "    eps_hat = model(x, t)\n",
    "    x = DDPM_UPDATE(x, eps_hat, t, tm1)\n",
    "return x\n",
    "```\n",
    "Note: If you encounter NaNs, you may need to clip $\\sigma_{t-1}^2 - \\eta_t^2$ to 0 if it goes negative, as machine precision issues can make it a very small negative number (e.g. -1e-12) if its too close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5315d3b-1726-418f-bc4f-6118c6aeb2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MlpBasedDiffuser(nn.Module):\n",
    "    def __init__(self, n_layers: int, hidden_size: int, dim: int):\n",
    "        super().__init__()\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        return x\n",
    "    \n",
    "\n",
    "class BaseTrainer:\n",
    "    def __init__(self, model: nn.Module, train_data: torch.FloatTensor, valid_data: torch.FloatTensor, batch_size: int, \n",
    "                 device: str, epochs: int):\n",
    "        self.model = model\n",
    "        self.train_loader = torch.utils.data.DataLoader(self.normalize(train_data), batch_size=batch_size)\n",
    "        self.valid_loader = torch.utils.data.DataLoader(self.normalize(valid_data), batch_size=batch_size)\n",
    "        self.object_shape = self.train_loader.dataset.shape[1:]\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=epochs)\n",
    "        self.epochs = epochs\n",
    "        self.device = device\n",
    "        self.model.to(device)\n",
    "\n",
    "    def normalize(self, data):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def restore(self, data):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def calc_loss(self, x):\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        return x\n",
    "\n",
    "    def eval_test_loss(self) -> float:\n",
    "        val_loss_accum = 0.\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for b in self.valid_loader:\n",
    "                l = self.calc_loss(b.to(self.device))\n",
    "                val_loss_accum += l.item()\n",
    "        return val_loss_accum / len(self.valid_loader)\n",
    "\n",
    "    \n",
    "    def train_cycle(self, verbose = False):\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        valid_losses.append(self.eval_test_loss())\n",
    "\n",
    "        for i in tqdm(range(self.epochs), total=self.epochs):\n",
    "            self.model.train()\n",
    "            for b in self.train_loader:\n",
    "                l = self.calc_loss(b.to(self.device))\n",
    "                train_losses.append(l.item())\n",
    "                self.optimizer.zero_grad()\n",
    "                l.backward()\n",
    "                self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            valid_losses.append(self.eval_test_loss())\n",
    "            if verbose:\n",
    "                print(f\"Epoch {i}: {valid_losses[-1]}\")\n",
    "        return np.array(train_losses), np.array(valid_losses)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def sample(self, n_samples, n_steps):\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        return x\n",
    "\n",
    "class Trainer2d(BaseTrainer):\n",
    "    def __init__(self, model: nn.Module, train_data: torch.FloatTensor, valid_data: torch.FloatTensor, batch_size: int, \n",
    "                 device: str, epochs: int):\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        super().__init__(model, train_data, valid_data, batch_size, device, epochs)\n",
    "\n",
    "    \n",
    "    def normalize(self, data):\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        return data\n",
    "\n",
    "    def restore(self, data):\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b6fe57-38f6-4859-a3f0-ff6fb571d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1(train_data, test_data):\n",
    "    \"\"\"\n",
    "    train_data: A (100000, 2) numpy array of 2D points\n",
    "    test_data: A (10000, 2) numpy array of 2D points\n",
    "\n",
    "    Returns\n",
    "    - a (# of training iterations,) numpy array of train losses evaluated every minibatch\n",
    "    - a (# of num_epochs + 1,) numpy array of test losses evaluated at the start of training and the end of every epoch\n",
    "    - a numpy array of size (9, 2000, 2) of samples drawn from your model.\n",
    "      Draw 2000 samples for each of 9 different number of diffusion sampling steps\n",
    "      of evenly logarithmically spaced integers 1 to 512\n",
    "      hint: np.power(2, np.linspace(0, 9, 9)).astype(int)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    \n",
    "    return train_losses, test_losses, all_samples\n",
    "\n",
    "q1_save_results(q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3052fc37-17f9-4e1f-8dfd-3289cb3b4403",
   "metadata": {},
   "source": [
    "# Question 2: Pixel-Space Diffusion on CIFAR-10\n",
    "\n",
    "In this question, we will train pixel-space UNet diffusion model on CIFAR-10\n",
    "\n",
    "Execute the cell below to visualize our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614910ac-a529-455c-a6f3-207eaa849256",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_q2_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad27d94-25e4-4b84-a210-648ef5998c8a",
   "metadata": {},
   "source": [
    "We'll use a UNet architecture similar to the original [DDPM](https://arxiv.org/abs/2006.11239) paper. We provide the following pseudocode for each part of the model:\n",
    "```\n",
    "def timestep_embedding(timesteps, dim, max_period=10000):\n",
    "    half = dim // 2\n",
    "    freqs = np.exp(-np.log(max_period) * np.arange(0, half, dtype=float32) / half)\n",
    "    args = timesteps[:, None].astype(float32) * freqs[None]\n",
    "    embedding = cat([np.cos(args), np.sin(args)], axis=-1)\n",
    "    if dim % 2:\n",
    "        embedding = cat([embedding, np.zeros_like(embedding[:, :1])], axis=-1)\n",
    "    return embedding\n",
    "\n",
    "ResidualBlock(in_channels, out_channels, temb_channels)\n",
    "    Given x, temb\n",
    "    h = Conv2d(in_channels, out_channels, 3, padding=1)(x)\n",
    "    h = GroupNorm(num_groups=8, num_channels=out_channels)(h)\n",
    "    h = SiLU()(h)\n",
    "    \n",
    "    temb = Linear(temb_channels, out_channels)(temb)\n",
    "    h += temb[:, :, None, None] # h is BxDxHxW, temb is BxDx1x1\n",
    "    \n",
    "    h = Conv2d(out_channels, out_channels, 3, padding=1)(h)\n",
    "    h = GroupNorm(num_groups=8, num_channels=out_channels)(h)\n",
    "    h = SiLU()(h)\n",
    "    \n",
    "    if in_channels != out_channels:\n",
    "        x = Conv2d(in_channels, out_channels, 1)(x)\n",
    "    return x + h\n",
    "    \n",
    "Downsample(in_channels)\n",
    "    Given x\n",
    "    return Conv2d(in_channels, in_channels, 3, stride=2, padding=1)(x)\n",
    "\n",
    "Upsample(in_channels)\n",
    "    Given x\n",
    "    x = interpolate(x, scale_factor=2)\n",
    "    x = Conv2d(in_channels, in_channels, 3, padding=1)(x)\n",
    "    return x\n",
    "    \n",
    "UNet(in_channels, hidden_dims, blocks_per_dim)\n",
    "    Given x, t\n",
    "    temb_channels = hidden_dims[0] * 4\n",
    "    emb = timestep_embedding(t, hidden_dims[0])\n",
    "    emb = Sequential(Linear(hidden_dims[0], temb_channels), SiLU(), Linear(temb_channels, temb_channels))(emb)\n",
    "    \n",
    "    h = Conv2d(in_channels, hidden_dims[0], 3, padding=1)(x)\n",
    "    hs = [h]\n",
    "    prev_ch = hidden_dims[0]\n",
    "    down_block_chans = [prev_ch]\n",
    "    for i, hidden_dim in enumerate(hidden_dims):\n",
    "        for _ in range(blocks_per_dim):\n",
    "            h = ResidualBlock(prev_ch, hidden_dim, temb_channels)(h, emb)\n",
    "            hs.append(h)\n",
    "            prev_ch = hidden_dim\n",
    "            down_block_chans.append(prev_ch)\n",
    "        if i != len(hidden_dims) - 1:\n",
    "            h = Downsample(prev_ch)(h)\n",
    "            hs.append(h)\n",
    "            down_block_chans.append(prev_ch)\n",
    "    \n",
    "    h = ResidualBlock(prev_ch, prev_ch, temb_channels)(h, emb)\n",
    "    h = ResidualBlock(prev_ch, prev_ch, temb_channels)(h, emb)\n",
    "    \n",
    "    for i, hidden_dim in list(enumerate(hidden_dims))[::-1]:\n",
    "        for j in range(blocks_per_dim + 1):\n",
    "            dch = down_block_chans.pop()\n",
    "            h = ResidualBlock(prev_ch + dch, hidden_dim, temb_channels)(cat(h, hs.pop()), emb)\n",
    "            prev_ch = hidden_dim\n",
    "            if i and j == blocks_per_dim:\n",
    "                h = Upsample(prev_ch)(h)\n",
    "    \n",
    "    h = GroupNorm(num_groups=8, num_channels=prev_ch)(h)\n",
    "    h = SiLU()(h)\n",
    "    out = Conv2d(prev_ch, in_channels, 3, padding=1)(h)\n",
    "    return out\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5b1f71-add7-4bcb-965b-609079225c04",
   "metadata": {},
   "source": [
    "**Hyperparameter details**\n",
    "* Normalize data to [-1, 1]\n",
    "* UNET with hidden_dims as [64, 128, 256, 512] and 2 blocks_per_dim\n",
    "* Train 60 epochs, batch size 256, Adam with LR 1e-3 (100 warmup steps, cosine decay to 0)\n",
    "* For diffusion schedule, sampling and loss, use the same setup as Q1\n",
    "\n",
    "You may also find it helpful to clip $\\hat{x} = \\frac{x_t - \\sigma_t \\hat{\\epsilon}}{\\alpha_t}$ to [-1, 1] during each sampling step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c2c5f-b111-4927-a62f-599dbc744f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dims, blocks_per_dim, embed_expansion=4):\n",
    "        super().__init__()\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        return x\n",
    "\n",
    "\n",
    "class ImageTrainer(BaseTrainer):\n",
    "    def normalize(self, data):\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        return data\n",
    "\n",
    "    def restore(self, data):\n",
    "        \"\"\" YOUR CODE HERE \"\"\"\n",
    "        return data\n",
    "\n",
    "\n",
    "\n",
    "def q2(train_data, test_data):\n",
    "    \"\"\"\n",
    "    train_data: A (50000, 32, 32, 3) numpy array of images in [0, 1]\n",
    "    test_data: A (10000, 32, 32, 3) numpy array of images in [0, 1]\n",
    "\n",
    "    Returns\n",
    "    - a (# of training iterations,) numpy array of train losses evaluated every minibatch\n",
    "    - a (# of num_epochs + 1,) numpy array of test losses evaluated at the start of training and the end of every epoch\n",
    "    - a numpy array of size (10, 10, 32, 32, 3) of samples in [0, 1] drawn from your model.\n",
    "      The array represents a 10 x 10 grid of generated samples. Each row represents 10 samples generated\n",
    "      for a specific number of diffusion timesteps. Do this for 10 evenly logarithmically spaced integers\n",
    "      1 to 512, i.e. np.power(2, np.linspace(0, 9, 10)).astype(int)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" YOUR CODE HERE \"\"\"\n",
    "    \n",
    "    return train_losses, test_losses, all_samples\n",
    "\n",
    "q2_save_results(q2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
